<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>煤与焦炭基本知识</title>
      <link href="/2022/08/24/Coking%20knowledge_2022_8_24/"/>
      <url>/2022/08/24/Coking%20knowledge_2022_8_24/</url>
      
        <content type="html"><![CDATA[<h2 id="1-煤炭的形成以及分类"><a href="#1-煤炭的形成以及分类" class="headerlink" title="1. 煤炭的形成以及分类"></a>1. 煤炭的形成以及分类</h2><h3 id="1-1-煤炭的形成"><a href="#1-1-煤炭的形成" class="headerlink" title="1.1 煤炭的形成"></a>1.1 煤炭的形成</h3><p>煤是由<strong>植物遗骸</strong>经煤化作用后形成的<strong>富碳可燃有机岩石</strong>, 由于成煤植物和条件不同，造成了煤的多样性，决定煤的性质主要有两阶段，分别是<strong>地球生物化学作用和地球物理化学作用阶段</strong>。</p><p><strong>地球生物化学作用</strong>：泥炭化作用，指植物遗骸被沼泽、湖泊等<strong>微生物进行分解</strong>，低等植物形成<strong>腐泥</strong>，高等植物形成<strong>泥炭</strong>。<br>泥炭化作用可细分为两个阶段：1）植物遗体经氧化水解成性质活泼的<strong>简单化合物</strong>  2）简单化合物经过相互作用形成<strong>稳定的有机化合物（含碳）</strong>，如<strong>腐殖酸和沥青质</strong>，这些产物以及植物残骸中未分解或者未完全分解的纤维素、半纤维素、果胶质和木质素等共同形成了<strong>泥炭</strong>.</p><p><strong>地球物理化学作用</strong>：变质作用，泥炭在地壳下降时，在上层沉积物的压力下，发生<strong>失水，胶体老化，固结</strong>等一系列变化形成<strong>褐煤</strong>。褐煤继续沉降，再更高的<strong>地温和压力</strong>下，内部分子发生变化，如<strong>芳香环缩合程度提高</strong>，<strong>官能团减少，侧链缩短、减少，结构单元增大</strong>等，经过不同程度的变质作用依次转变为<strong>烟煤，无烟煤，超无烟煤</strong>，甚至在特殊情况下直接变成<strong>石墨</strong>。</p><p>在泥炭形成前是地球生物化学作用，泥炭形成后是地球物理化学作用。</p><h3 id="1-2-煤炭的分类"><a href="#1-2-煤炭的分类" class="headerlink" title="1.2 煤炭的分类"></a>1.2 煤炭的分类</h3><p>煤可分为两类：<strong>腐殖煤与腐泥煤</strong>，高等植物形成的是<strong>腐殖煤</strong>，低等植物形成的是<strong>腐泥煤</strong>。有时还有他们的混合体，即<strong>腐殖腐泥煤</strong>。腐殖煤可分为：<strong>泥炭，褐煤，烟煤，无烟煤</strong>四个大类。</p><p><strong>泥炭</strong>：泥炭是植物遗骸向煤转变时经地球生物化学作用形成的<strong>过渡产物</strong>。外观呈棕褐色或黑褐色，易分辨。含水量高达75%-95%。含硫量低，平均为0.3%，属于<strong>低硫燃料</strong>。</p><p><strong>褐煤</strong>：泥炭在沉积后经过<strong>脱水，压实等过程</strong>，转变成有机沉积岩的<strong>初期产物</strong>。因外观为<strong>褐色或暗褐色</strong>，因此被称为<strong>褐煤</strong>。与泥炭相比，褐煤的芳香核缩合程度增加，含氧官能团减少，但仍保持较大的含氧量。侧链较短且数量也较少。褐煤含水量达30%-60%，褐煤呈层状分布，没有未分解的植物残骸。<strong>褐煤</strong>占全国煤炭储量的**17%**，其含水量多，易风化破碎，不适合长途运输。</p><p><strong>烟煤</strong>：烟煤因燃烧时烟多而闻名。是自然界中分布最广，储量最大，种类最多，利用最广泛的煤。我国分为12大类24小类。烟煤中，随着煤化度增加，从气煤到瘦煤各煤种因具有不同程度的黏结性，经破碎高温干馏后，可不同程度地经<strong>软化、熔融成为塑性体</strong>，然后再固化成为块状焦。这些煤是炼焦的主要原料煤，故称为<strong>炼焦煤</strong>；此外其他煤种无黏结性，称为<strong>非炼焦煤</strong>。</p><p><strong>无烟煤</strong>：煤化度最高。因燃烧过程没有烟因被称为<strong>无烟煤</strong>。外观呈灰黑色，略带金属光泽。挥发分最低，碳含量最高，其主要作为燃料。</p><p><img src="/./img/Blog_img/14.jpg" alt="markdown"><br>图片中，煤化度从下到上，依次增高，没有y胶质层的指标是因为那些煤无法生成胶质体。</p><h2 id="2-炼焦煤在配煤炼焦过程中的作用"><a href="#2-炼焦煤在配煤炼焦过程中的作用" class="headerlink" title="2. 炼焦煤在配煤炼焦过程中的作用"></a>2. 炼焦煤在配煤炼焦过程中的作用</h2><p>在煤炭分类中，只有烟煤含有<strong>炼焦煤</strong>。虽然他们可单独炼焦，但优质炼焦煤少，因此一般采用配煤炼焦，即使用两种或两种以上的炼焦煤或一定量的非炼焦煤。</p><p><strong>气煤</strong>：低变质程度，挥发分高，黏结性弱，热解生成较多<strong>挥发性气体和焦油</strong>，气孔率较高，炼焦副产物多，胶质体稳定性差，抗碎程度差，多配入气煤，可以增加煤气和副产品产量。<br><strong>气肥煤</strong>：高挥发分强黏结性炼焦煤，结焦性比气煤好，但比肥煤差，挥发分高，炼焦可产生较多挥发分气体或副产品。<br><strong>1&#x2F;3焦煤</strong>：中高挥发分强黏结性炼焦煤，结焦性能类似焦煤，因此称为1&#x2F;3焦煤。<br><strong>肥煤</strong>：肥煤是一种中挥发分强黏结性炼焦煤。它是所有炼焦煤中<strong>黏结性最好</strong>的煤种。热解时产生<strong>大量的胶质体，且热稳定性好</strong>。但单独炼焦时其焦炭裂纹多，而强度却很高。一般作为配煤炼焦的基础煤种。<br><strong>焦煤</strong>：中挥发分强黏结性炼焦煤。它是所有炼焦煤中<strong>结焦性最好</strong>的煤种。单独炼焦时得到的焦炭块度大、裂纹少、强度高，但膨胀压力大，收缩度小，<strong>容易产生推焦困难</strong>，损坏炉墙。<br><strong>廋煤</strong>：低挥发分中低黏结性炼焦煤。单独炼焦时得到的焦炭块度大，裂纹少。但因其<strong>黏结性不足</strong>，惰性组分熔融不充分，焦炭界面结合较差，故其焦炭抗碎强度和耐磨强度都较差。配煤炼焦时可加入<strong>瘦煤</strong>作为瘦化剂，<strong>增大焦炭块度，减少裂纹</strong>。</p><h2 id="3-煤的热解及成焦机理"><a href="#3-煤的热解及成焦机理" class="headerlink" title="3. 煤的热解及成焦机理"></a>3. 煤的热解及成焦机理</h2><h3 id="3-1-煤的热解过程"><a href="#3-1-煤的热解过程" class="headerlink" title="3.1 煤的热解过程"></a>3.1 煤的热解过程</h3><p>煤的热解指的是煤在隔绝空气或惰性条件下持续加热升温发生的一系列<strong>物理化学变化</strong>，并生成<strong>煤气、焦油、半焦和焦炭</strong>等产物的过程。过程中，<strong>化学键的断裂</strong>是基本的行为。</p><p><strong>第一阶段：干燥脱气阶段（室温-350°）</strong>：该过程煤的外形几乎无变化，煤在<strong>100°</strong>时首先经过干燥脱去水分，在<strong>200°</strong>时脱去煤吸附的N2,CH4,CO2等气体。<strong>200°以上</strong>，褐煤可以发生部分脱羧基反应。</p><p><strong>第二阶段：解聚分解阶段（350-500°）</strong>：煤分子活泼的热分解，烟煤约<strong>350°</strong>开始软化，然后熔融、黏结，在<strong>550°</strong>结成半焦，该过程生成焦油和大量的挥发物（煤气）。在<strong>450°-550°</strong>温度范围气体析出量最多，约<strong>450°</strong>生成的焦油量最大。<br>中煤化度煤在该阶段生成大量黏稠液体，称为<strong>胶质体</strong>，它为<strong>三相混合物</strong>，气液固三相共存的黏稠状物体，胶质体有黏结性，是炼焦煤能成块的<strong>重要原因</strong>。煤的黏结性和结焦性由胶质体的数量和性质决定。<br>温度升高到<strong>480°-550°</strong>时，胶质体的液相进一步分解，分解得到的小分子及气态析出，残留部分则固化形成<strong>半焦</strong>。半焦和原煤相比，芳香层片平均尺寸有所增加但变化不大，说明在半焦生成过程中缩聚反应并不激烈。</p><p><strong>第三阶段：二次脱气阶段（550-1000°）</strong>：主要以缩聚反应为主，半焦经收缩形成焦炭。该过程析出焦油量极少，产生气体主要是<strong>H2和少量的CH4、碳氧化物等</strong>。在<strong>700°</strong>时反应较为明显和激烈。约在750-1000°时，继续有少量H2放出，芳香碳网不断增大、排列致密、密度增加，半焦强烈收缩变成焦炭。<br>此过程由于大量煤气析出使挥发分降低，<strong>形成气孔</strong>，同时由于焦炭本身密度的增加，<strong>焦炭体积收缩，导致产生裂纹</strong>。焦炭的块度和强度与收缩程度有关，<strong>收缩越剧烈，强度越差，块度越小</strong>。</p><p>低煤化度煤（如褐煤）热解过程与烟煤大致相同，<strong>但热解过程中不能形成胶质体，仅分解产生气体和部分焦油</strong>，得到粉状的固体残留物。高煤化度煤（如无烟煤）热解过程则更简单，在加热升温过程中，<strong>既无胶质体的形成，也无焦油产生，仅有少量热解气体放出</strong>，因此无烟煤不宜采用干馏加工。</p><p><img src="/./img/Blog_img/15.jpg" alt="markdown"></p>]]></content>
      
      
      <categories>
          
          <category> 炼焦学 </category>
          
          <category> 煤与焦炭 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 炼焦学 </tag>
            
            <tag> 煤与焦炭 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch第二章预备知识-线性代数</title>
      <link href="/2022/07/07/Pytorch_linear_algebra_2022_7_7/"/>
      <url>/2022/07/07/Pytorch_linear_algebra_2022_7_7/</url>
      
        <content type="html"><![CDATA[<h2 id="1-标量"><a href="#1-标量" class="headerlink" title="1. 标量"></a>1. 标量</h2><p><strong>标量</strong>：仅包含<strong>一个数值</strong>的称为标量，根据数学表示法，标量通常由<strong>小写字母表示</strong>，此外，通常用R来表示所有连续的实数标量空间。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">x = torch.tensor(3.0)</span><br><span class="line">y = torch.tensor(2.0)</span><br><span class="line"></span><br><span class="line">x + y, x * y, x/y, x**y</span><br></pre></td></tr></table></figure><h2 id="2-向量"><a href="#2-向量" class="headerlink" title="2. 向量"></a>2. 向量</h2><p><strong>向量</strong>：向量是标量组成的列表，在pytorch里通过一维张量来处理向量，张量可以有任意长度，取决于机器内存限制。通常用x_i来表示引用第i个元素。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.arange(4)</span><br><span class="line">x[3]</span><br></pre></td></tr></table></figure><p>如果一个向量由n个实值标量组成，我们可以将其表示成：$$x \in R^n$$，其中向量的长度我们通常称为<strong>维度</strong>。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">len(x) # 访问张量的长度</span><br></pre></td></tr></table></figure><p>维度有时候会引起歧义，因此规定了：向量或轴的维度被用来表示<strong>向量或轴的长度</strong>，即向量或轴的元素数量。 然而，张量的维度用来表示张量<strong>具有的轴数</strong>。 在这个意义上，张量的某个轴的维数就是这个轴的长度。</p><h2 id="3-矩阵"><a href="#3-矩阵" class="headerlink" title="3. 矩阵"></a>3. 矩阵</h2><p>通常用粗体X,Y,Z等来表示矩阵，矩阵在代码中表示有两个轴的张量。数学表示法中用A \in R^(mxn) 来表示矩阵A，其由m行n列的实值标量组成。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">A = torch.arange(20).reshape(5, 4) # 生成矩阵</span><br><span class="line">A.T # 矩阵转置</span><br><span class="line">B = torch.tensor([[1, 2, 3], [2, 0, 4], [3, 4, 5]]) # 对称矩阵，矩阵本身等于它的转置</span><br><span class="line">B == B.T</span><br></pre></td></tr></table></figure><p>尽管单个向量的默认方向是列向量，但在表示表格数据集的矩阵中， 将每个数据样本作为矩阵中的行向量更为常见。</p><h2 id="4-张量"><a href="#4-张量" class="headerlink" title="4. 张量"></a>4. 张量</h2><ol><li><p>张量加法</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">A = torch.arange(20, dtype=torch.float32).reshape(5,4))</span><br><span class="line">B = A.clone() # 通过分配新内存，将A的一个副本分配给B, A改变B不会改变</span><br><span class="line">A, A+B </span><br></pre></td></tr></table></figure></li><li><p>张量乘法<br>两个矩阵的按元素乘法称为哈达码积 (Hadamard积, Hadamard product）（数学符号⊙），如果是向量的按元素乘法，则称为点积，而且点积会计算和，哈达码积不会。<br><img src="/./img/Blog_img/7.png" alt="markdown"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A*B # A*B是对应元素相乘，如果是矩阵相乘，则用A@B或torch.matmul(A,B)</span><br></pre></td></tr></table></figure><p>将张量乘以或加上一个标量不会改变张量的形状，其中张量的每个元素都将与标量相加或相乘。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = 2</span><br><span class="line">X = torch.arange(24).shape(2,3,4)</span><br><span class="line">X+a, X*a</span><br></pre></td></tr></table></figure></li></ol><h2 id="5-降维求和"><a href="#5-降维求和" class="headerlink" title="5. 降维求和"></a>5. 降维求和</h2><p>调用求和函数会沿所有的轴降低张量的维度，使它变为一个标量。</p><ol><li><p>向量求和</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.arange(4, dtype=torch.float32)</span><br><span class="line">x, x.sum()</span><br></pre></td></tr></table></figure></li><li><p>矩阵求和</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">A = torch.arange(20, dtype=torch.float32).reshape(5,4))</span><br><span class="line">A_sum_axis0 = A.sum(axis=0) # 按行的方向来进行求和</span><br><span class="line">A_sum_axis0, A_sum_axis0.shape</span><br><span class="line"></span><br><span class="line">A_sum_axis0 = A.sum(axis=1) # 按列的方向来进行求和</span><br><span class="line">A_sum_axis0, A_sum_axis0.shape</span><br><span class="line"></span><br><span class="line">A.sum(axis=[0, 1])  # 沿着行和列对矩阵求和，等价于对矩阵的所有元素进行求和。</span><br><span class="line"></span><br><span class="line">A.mean() # 求平均值</span><br><span class="line">A.sum()/A.numel() # 求平均值</span><br><span class="line"></span><br><span class="line">A.mean(axis=0), A.sum(axis=0) / A.shape[0] # 也可以沿着某一轴进行平均值的计算</span><br></pre></td></tr></table></figure></li></ol><h2 id="6-非降维求和"><a href="#6-非降维求和" class="headerlink" title="6. 非降维求和"></a>6. 非降维求和</h2><p>有时在调用函数来计算总和或均值时保持轴数不变会很有用。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sum_A = A.sum(axis=1, keepdims=True) # keepdims=True为保持维数不变</span><br><span class="line">sum_A</span><br></pre></td></tr></table></figure><p>由于sum_A在对每行进行求和后仍保持两个轴，我们可以通过广播机制将A除以sum_A。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A / sum_A</span><br></pre></td></tr></table></figure><p>如果想沿某个轴计算A元素的<strong>累积总和</strong>，可以用cumsum函数。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A.cumsum(axis=0) # 沿着行的方向来计算累计总和</span><br></pre></td></tr></table></figure><h2 id="7-点积-Dot-product"><a href="#7-点积-Dot-product" class="headerlink" title="7. 点积(Dot product)"></a>7. 点积(Dot product)</h2><p>给定两个向量X,Y \in R^n，它们的点积为x^Ty(或&lt;x,y&gt;)是指相同位置的按元素乘积的和</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = torch.arange(4, dtype=torch.float32)</span><br><span class="line">y = torch.ones(4,dtype=torch.float32)</span><br><span class="line">x, y, torch.dot(x,y) #结果等于6</span><br></pre></td></tr></table></figure><p>x^Tw, 当权重w为非负数且所有的w和为1时，点积表示为加权平均。 将两个向量规范化得到单位长度后，点积表示它们夹角的余弦。</p><h2 id="8-矩阵-向量积"><a href="#8-矩阵-向量积" class="headerlink" title="8. 矩阵-向量积"></a>8. 矩阵-向量积</h2><p>定义矩阵 A \in R^(mxn)和向量x \in R^n, 矩阵A用它的行向量来表示：<br><img src="/./img/Blog_img/13.jpg" alt="markdown"><br>其中每个(a_1)^T都是行向量，矩阵向量积Ax是一个长度为m的列向量,其中第i个元素是a和x的点积分<br><img src="/./img/Blog_img/7.png" alt="markdown"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A.shape, x.shape, torch.mv(A, x) # 当我们为矩阵A和向量x调用torch.mv(A, x)时，会执行矩阵-向量积</span><br></pre></td></tr></table></figure><h2 id="9-矩阵-矩阵乘法"><a href="#9-矩阵-矩阵乘法" class="headerlink" title="9. 矩阵-矩阵乘法"></a>9. 矩阵-矩阵乘法</h2><p><img src="/./img/Blog_img/9.jpg" alt="markdown"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">A = torch.arange(20, dtype=torch.float32).reshape(5,4))</span><br><span class="line">B = torch.ones(4,3)</span><br><span class="line">torch.mm(4,3)</span><br></pre></td></tr></table></figure><h2 id="10-范数"><a href="#10-范数" class="headerlink" title="10. 范数"></a>10. 范数</h2><p>一个向量的范数告诉我们向量有多大，这里大小指的是分量的大小，向量范数是将向量映射到标量的函数f。<br>范数的四个性质：<br><img src="/./img/Blog_img/10.jpg" alt="markdown"></p><ol><li><p>L2范数：范数是向量元素平方和的平方根，其中L_2范数经常省略下标2，也就是说||x||等同于||x||_2，在深度学习中更常用L2范数的平方。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">u = torch.tensor([3.0, -4.0])</span><br><span class="line">torch.norm(u) # 得到L_2范数，结果为5</span><br></pre></td></tr></table></figure></li><li><p>L1范数：向量元素的绝对值之和，其与L_2范数相比，受异常值的影响较小<br><img src="/./img/Blog_img/11.jpg" alt="markdown"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.abs(u).sum()</span><br></pre></td></tr></table></figure></li><li><p>Lp范数：L2和L1范数是Lp范数的特例<br><img src="/./img/Blog_img/12.jpg" alt="markdown"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.norm(torch.ones((4, 9)))</span><br></pre></td></tr></table></figure></li></ol>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
          <category> 动手学深度学习 </category>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch第二章预备知识-数据操作+数据预处理</title>
      <link href="/2022/07/04/Pytorch_data_operation_2022_7_4/"/>
      <url>/2022/07/04/Pytorch_data_operation_2022_7_4/</url>
      
        <content type="html"><![CDATA[<p>近日一直不断观看李沐沐神的视频和书籍，想把自己的基础知识再进行不断地巩固，同时也希望可以从大神身上学习到更多系统性方面的知识和他对于这个领域的不同见解和观点，因此后续会不断更新该系列博客，将会从此书的最开头基础部分开始不断记录学习到的知识点。</p><h2 id="1-入门"><a href="#1-入门" class="headerlink" title="1. 入门"></a>1. 入门</h2><ol><li><p><strong>张量</strong>：n维数组。<strong>Tensorflow、pytorch、numpy</strong>的数据格式都是n维数组，结构类似，在Tensorflow和Pytorch中称为张量。一个轴称为<strong>向量</strong>，两个轴称为<strong>矩阵</strong>，两个轴以上的没有特殊名称。Tensor是数学上的概念，数组是计算机上的概念。<br><strong>区别</strong>：Numpy只支持CPU运算，而张量支持GPU加速运算和自动微分</p></li><li><p>基本数据操作</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line"></span><br><span class="line">x = torch.range(12) # 创建0-11的向量</span><br><span class="line"></span><br><span class="line">x.shape # 访问形状</span><br><span class="line"></span><br><span class="line">x.numel() # 得到张量中元素的总数</span><br><span class="line"></span><br><span class="line">x = x.reshape(3,4) # 改变张量的形状，变成(3,4)</span><br><span class="line"></span><br><span class="line">x = x.reshape(-1, 4) # -1代表自动计算那个维度的值</span><br><span class="line"></span><br><span class="line">torch.zeros((2,3,4)) # 创建全0</span><br><span class="line">torch.ones((2,3,4)) # 创建全1</span><br><span class="line"></span><br><span class="line">torch.randn(3,4) # 在均值为0，标准差为1的高斯正态分布中随机采样来得到张量中每个元素的值</span><br><span class="line"></span><br><span class="line">torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]]) # 用列表创建张量</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure></li></ol><h2 id="2-运算符"><a href="#2-运算符" class="headerlink" title="2. 运算符"></a>2. 运算符</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([1,2,4,8])</span><br><span class="line">y = torch.tensor([2,2,2,2])</span><br><span class="line">x+y,x-y,x*y,x/y,x**y #基本运算</span><br><span class="line"></span><br><span class="line">torch.exp(x) #求指数</span><br><span class="line"></span><br><span class="line">X = torch.arange(12,dtype=torch.float32).reshape((3,4))</span><br><span class="line">Y = torch.tensor([[2,1,4,3],[1,2,3,4],[4,3,2,1]])</span><br><span class="line">torch.cat((X,Y),dim=0),torch.cat((X,Y),dim=1) # dim=0按行方向拼接，dim=1按列方向拼接</span><br><span class="line"></span><br><span class="line">X==Y #对应位置是否相等，如果相等则True，否则False</span><br><span class="line"></span><br><span class="line">X.sum() # 对里面所有元素进行求和，输出一个值</span><br></pre></td></tr></table></figure><h2 id="3-广播机制"><a href="#3-广播机制" class="headerlink" title="3. 广播机制"></a>3. 广播机制</h2><p>形状不同，也可以调用广播机制来执行元素操作，机制：复制元素扩展一或两个数组，以便转换后，两个张量有相同形状，之后按元素操作</p><p>输入以下指令开启服务端服务(需要先开启这个，再开启客户端)</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = torch.arange(3).reshape((3,1))</span><br><span class="line">b = torch.arange(2).reshape((1,2))</span><br><span class="line"></span><br><span class="line">a+b # 会把a按列复制成3x2，接着把b按行复制成3x2，最后相加</span><br></pre></td></tr></table></figure><h2 id="4-索引和切片"><a href="#4-索引和切片" class="headerlink" title="4. 索引和切片"></a>4. 索引和切片</h2><p>张量的元素也可以通过索引访问</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">X = torch.arange(12,dtype=torch.float32).reshape((3,4))</span><br><span class="line">X[-1] # 取最后一行</span><br><span class="line">X[1:3] # 取第二第三行</span><br><span class="line">X[1,2] = 9 # 指定索引，将元素写入矩阵</span><br><span class="line">X[0:2, :] = 12 # 给第一第二行，所有列赋值</span><br><span class="line">X[::3,::2] # 第一个到最后一个，隔三行取一个值，隔二列取一个值</span><br></pre></td></tr></table></figure><h2 id="5-节省内存"><a href="#5-节省内存" class="headerlink" title="5. 节省内存"></a>5. 节省内存</h2><p>运行一些操作可能会导致为新结果分配内存。 例如，如果我们用Y &#x3D; X + Y，我们将取消引用Y指向的张量，而是指向新分配的内存处的张量。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">before = id(Y) # Y原先的内存位置</span><br><span class="line">Y = Y + X</span><br><span class="line">id(Y) == before #判断Y改变后的内存位置和原先位置是否相等</span><br></pre></td></tr></table></figure><p>该操作是不可取的，机器学习中，我们可能有数百兆的参数，我们希望原地执行这些更新。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Z = torch.zeros_like(Y)</span><br><span class="line">print(&#x27;id(Z):&#x27;, id(Z))</span><br><span class="line">Z[:] = X + Y</span><br><span class="line">print(&#x27;id(Z):&#x27;, id(Z)) #id与之前相同</span><br></pre></td></tr></table></figure><p>如果在后续计算中没有重复使用X，我们也可以使用X[:] &#x3D; X + Y或X +&#x3D; Y来减少操作的内存开销:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">before = id(X)</span><br><span class="line">X += Y</span><br><span class="line">id(X) == before</span><br></pre></td></tr></table></figure><h2 id="6-转换为其它Python对象"><a href="#6-转换为其它Python对象" class="headerlink" title="6. 转换为其它Python对象"></a>6. 转换为其它Python对象</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">A = X.numpy() # 转换成numpy格式</span><br><span class="line">B = torch.tensor(A) # 转换回Tensor</span><br><span class="line"></span><br><span class="line">a = torch.tensor([3.5])</span><br><span class="line">a.item() # 转换成Python标量</span><br><span class="line">float(a)</span><br><span class="line">int(a)</span><br></pre></td></tr></table></figure><h2 id="7-数据预处理实战"><a href="#7-数据预处理实战" class="headerlink" title="7. 数据预处理实战"></a>7. 数据预处理实战</h2><ol><li><p><strong>读取数据</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line"></span><br><span class="line">os.makedirs(os.path.join(&#x27;.&#x27;, &#x27;data&#x27;), exist_ok=True) # 创建一个文件夹</span><br><span class="line">data_file = os.path.join(&#x27;.&#x27;, &#x27;data&#x27;, &#x27;house_tiny.csv&#x27;) # 定义要创建的文件路径</span><br><span class="line">with open(data_file, &#x27;w&#x27;) as f: # 创建一个文件</span><br><span class="line">    f.write(&#x27;NumRooms,Alley,Price\n&#x27;)  # 列名</span><br><span class="line">    f.write(&#x27;NA,Pave,127500\n&#x27;)  # 每行表示一个数据样本</span><br><span class="line">    f.write(&#x27;2,NA,106000\n&#x27;) # 写入数据</span><br><span class="line">    f.write(&#x27;4,NA,178100\n&#x27;)</span><br><span class="line">    f.write(&#x27;NA,NA,140000\n&#x27;)</span><br><span class="line"></span><br><span class="line">import pandas as pd</span><br><span class="line">data = pd.read_csv(data_file) # 读取数据</span><br><span class="line">print(data)</span><br></pre></td></tr></table></figure></li><li><p><strong>处理缺失值</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">inputs, outputs = data.iloc[:, 0:2], data.iloc[:,2]</span><br><span class="line">inputs = inputs.fillna(inputs.mean()) # 用均值填充缺失值</span><br><span class="line">print(inputs)</span><br><span class="line">inputs = pd.get_dummies(inputs, dummy_na=True) # one-hot编码，dummy_na对na也进行编码</span><br></pre></td></tr></table></figure></li><li><p><strong>转换为张量格式</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line"></span><br><span class="line">X,y = torch.tensor(inputs.values), torch.tensor(outputs.values)</span><br><span class="line">X,y</span><br></pre></td></tr></table></figure></li></ol><h2 id="8-QA"><a href="#8-QA" class="headerlink" title="8. QA"></a>8. QA</h2><ol><li><p>reshape和view区别？<br>reshape和view不相同，view该操作不会开辟新的内存空间，只是产生了对原存储空间的一个新别称和引用，返回值是视图，视图值改变，原先的值也会改变。而reshape则可以开辟新的内存空间，可以是视图，也可以是新内存空间的副本。</p></li><li></li></ol>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
          <category> 动手学深度学习 </category>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>利用FRP实现内网穿透</title>
      <link href="/2022/06/26/FTP%20Intranet%20through_2022_6_25/"/>
      <url>/2022/06/26/FTP%20Intranet%20through_2022_6_25/</url>
      
        <content type="html"><![CDATA[<p>此贴记录如何通过FRP技术实现内网穿透，使通过公网指定端口可以访问至内网。FRP是一个专注于内网穿透的高性能的反向代理应用，支持 TCP、UDP、HTTP、HTTPS 等多种协议。可以将内网服务以安全、便捷的方式通过具有公网 IP 节点的中转暴露到公网。</p><h2 id="1-下载FRP库"><a href="#1-下载FRP库" class="headerlink" title="1. 下载FRP库"></a>1. 下载FRP库</h2><p>在指定文件下右键Git bash打开终端并输入以下指令下载指定版本的FRP库,不同版本链接：<a href="https://github.com/fatedier/frp/releases">https://github.com/fatedier/frp/releases</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo wget https://github.com/fatedier/frp/releases/download/v0.43.0/frp_0.43.0_linux_amd64.tar.gz</span><br></pre></td></tr></table></figure><p><img src="/./img/Blog_img/3.jpg" alt="markdown"></p><h2 id="2-解压FRP压缩包"><a href="#2-解压FRP压缩包" class="headerlink" title="2. 解压FRP压缩包"></a>2. 解压FRP压缩包</h2><p>输入以下指令进行解压(内网和外网均需要)。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf frp_0.43.0_linux_amd64.tar.gz</span><br></pre></td></tr></table></figure><h2 id="3-服务端配置文件"><a href="#3-服务端配置文件" class="headerlink" title="3. 服务端配置文件"></a>3. 服务端配置文件</h2><p>进入服务端(外网)解压的文件夹目录，之后使用以下指令打开配置文件。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim frps.ini</span><br></pre></td></tr></table></figure><p>根据下图进行配置，图中bind_port是FRP通讯的端口，要和客户端(内网)保持一致，vhost是外网开放的端口(通过外网哪个端口访问到内网服务)，同时可能需要提前关闭防火墙或打开指定端口。<br><img src="/./img/Blog_img/4.png" alt="markdown"></p><p>输入以下指令开启服务端服务(需要先开启这个，再开启客户端)</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./frps -c ./frps.ini</span><br></pre></td></tr></table></figure><h2 id="4-客户端配置文件"><a href="#4-客户端配置文件" class="headerlink" title="4. 客户端配置文件"></a>4. 客户端配置文件</h2><p>进入客户端(内网)解压的文件夹目录, 之后使用以下指令打开配置文件。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim frpc.ini</span><br></pre></td></tr></table></figure><p>根据下图进行配置，common中的地址是公网IP的地址，server_port要和上面的bind_port保持一致，web中local_port是客户端要映射的端口，remote_port是服务端开放的映射端口。<br><img src="/./img/Blog_img/5.png" alt="markdown"></p><p>输入以下指令开启客户端服务</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./frpc -c ./frpc.ini</span><br></pre></td></tr></table></figure><h2 id="5-通过systemctl来控制后台启动和开机自启"><a href="#5-通过systemctl来控制后台启动和开机自启" class="headerlink" title="5. 通过systemctl来控制后台启动和开机自启"></a>5. 通过systemctl来控制后台启动和开机自启</h2><p>输入以下指令创建新配置文件(frps和frpc):</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /lib/systemd/system/frps.service</span><br></pre></td></tr></table></figure><p>在文件中写入以下内容(服务端路径是frps，客户端路径是frpc)：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=fraps service</span><br><span class="line">After=network.target syslog.target</span><br><span class="line">Wants=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=simple</span><br><span class="line">#启动服务的命令（此处写你的frps的实际安装目录）</span><br><span class="line">ExecStart=/your/path/frps -c /your/path/frps.ini</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure><p>输入以下指令启动后台服务</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl start frps #启动frps</span><br><span class="line">sudo systemctl enable frps #打开自启动</span><br><span class="line">sudo systemctl restart frps #重启应用</span><br><span class="line">sudo systemctl stop frps #停止应用</span><br></pre></td></tr></table></figure><p><img src="/./img/Blog_img/6.png" alt="markdown"></p>]]></content>
      
      
      <categories>
          
          <category> FRP </category>
          
          <category> 内网穿透 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FRP 内网穿透 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>利用Hexo和Butterfly主题搭建个人博客流程</title>
      <link href="/2022/06/22/Building%20the%20blog_2022_6_23/"/>
      <url>/2022/06/22/Building%20the%20blog_2022_6_23/</url>
      
        <content type="html"><![CDATA[<p>此贴记录一下如何使用基于nodejs的静态博客网站生成器<strong>Hexo</strong>去生成一个个人博客，该教程以使用Butterfly主题为例进行演示。</p><h2 id="1-配置Github"><a href="#1-配置Github" class="headerlink" title="1. 配置Github"></a>1. 配置Github</h2><p>利用Github可以将本地建站的内容同步至云端存储空间中，同时利用github.io (每个账号只有一个) 提供的域名进行个人博客免费部署。</p><p>创建好Github后，建立一个为”用户名.github.io”形式的账号，并打开setting，如下图所示。同时注意要将该repo的权限变为public。</p><p><img src="/./img/Blog_img/1.jpg" alt="markdown"></p><h2 id="2-Git安装"><a href="#2-Git安装" class="headerlink" title="2. Git安装"></a>2. Git安装</h2><p>Git是一个开源的分布式版本控制系统，通过它可以方便地进行各大小项目的管理和其它人的协同合作。</p><p>进入<a href="https://git-scm.com/">Git官网</a>，下载并进行安装，全程基本点击Next即可。</p><p>下载完成后打开Git Bash，输入Git，若返回相关信息，则说明安装成功。<br><img src="/./img/Blog_img/2.jpg" alt="markdown"></p><h2 id="3-绑定Github账号"><a href="#3-绑定Github账号" class="headerlink" title="3. 绑定Github账号"></a>3. 绑定Github账号</h2><p>参考网上资料，主要是本地生成公钥密钥，然后将本地生成的公钥写入github账户中的SSH和GPGkeys这一栏中。</p><h2 id="4-利用Git提交文件的方法"><a href="#4-利用Git提交文件的方法" class="headerlink" title="4. 利用Git提交文件的方法"></a>4. 利用Git提交文件的方法</h2><h3 id="4-1-本地没有Git仓库"><a href="#4-1-本地没有Git仓库" class="headerlink" title="4.1 本地没有Git仓库"></a>4.1 本地没有Git仓库</h3><p>4.1.1 clone远程仓库的<strong>https</strong>链接<br>4.1.2 在<strong>git bash</strong>中输入<strong>git clone https链接</strong>，将远程仓库拷贝至本地<br>4.1.3 输入<strong>git status</strong>可以查看仓库状态，如果显示untracked则表示有些文件没被追踪<br>4.1.4 输入<strong>git add</strong>文件名将文件加入到缓冲区，再用<strong>git commit -m 提交信息</strong>至本地仓库，若为第一次提交则需要输入账号密码<br>4.1.5 输入<strong>git log</strong>可以查看提交记录<br>4.1.6 输入<strong>git push origin(主机名) master</strong>将本地仓库提交到远程仓库</p><h3 id="4-2-本地拥有Git仓库"><a href="#4-2-本地拥有Git仓库" class="headerlink" title="4.2 本地拥有Git仓库"></a>4.2 本地拥有Git仓库</h3><p>4.2.1 建立一个本地仓库，使用git init初始化该仓库<br>4.2.2 输入<strong>git remote add origin http链接</strong>关联远程仓库<br>4.2.3 输入<strong>git pull origin master</strong>同步远程和本地仓库，其它命令与4.1一致</p><h2 id="5-安装nodejs和Hexo"><a href="#5-安装nodejs和Hexo" class="headerlink" title="5. 安装nodejs和Hexo"></a>5. 安装nodejs和Hexo</h2><p>进入<a href="https://nodejs.org/en/">nodejs官网</a>下载nodejs并不断点击next完成安装。之后可在cmd中输入<strong>node -v</strong>查看版本。</p><p>在指定的文件夹下右键选择打开<strong>Git Bash Here</strong>并输入以下命令安装Hexo。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install -g hexo-cli</span><br></pre></td></tr></table></figure><p>安装之后输入<strong>hexo init</strong>命令初始化博客</p><p>输入以下指令生成静态文件：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo g</span><br></pre></td></tr></table></figure><p>输入以下指令运行服务器并在本地4000端口进行查看博客(修改文件时无需重启)：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo s</span><br></pre></td></tr></table></figure><p>还可以输入以下指令清除缓存文件 db.json 和已生成的静态文件：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo clean</span><br></pre></td></tr></table></figure><h2 id="6-将Hexo部署Github"><a href="#6-将Hexo部署Github" class="headerlink" title="6. 将Hexo部署Github"></a>6. 将Hexo部署Github</h2><p>在文件夹下打开全局配置文件**_config.yml**下滑到文件底部，输入以下内容：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">deploy:</span><br><span class="line">  type: git</span><br><span class="line">  repository: https://github.com/xxxxxx  #你的仓库地址</span><br><span class="line">  branch: master</span><br></pre></td></tr></table></figure><p>接着在git base中输入以下指令自动生成网站静态文件，并部署到设定的仓库，在这一步中可能需要验证账号：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo d</span><br></pre></td></tr></table></figure><h2 id="7-配置butterfly主题"><a href="#7-配置butterfly主题" class="headerlink" title="7. 配置butterfly主题"></a>7. 配置butterfly主题</h2><p>在git base中输入以下命令将butterfly主题拷贝至当前文件夹中：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/jerryc127/hexo-theme-butterfly.git</span><br></pre></td></tr></table></figure><p>在全局**_config.yml**文件中的Extensions处将主题进行修改，原主题进行注释</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">theme:butterfly</span><br></pre></td></tr></table></figure><h2 id="8-butterfly中注意事项"><a href="#8-butterfly中注意事项" class="headerlink" title="8. butterfly中注意事项"></a>8. butterfly中注意事项</h2><ul><li>在themes文件夹下的butterfly中也有一个主题配置文件_config.yml,具体配置指南可参考<a href="https://butterfly.js.org/">butterfly官网</a></li><li>网站标题、副标题和博主姓名、语言等可以在全局_config.yml文件中设置</li><li>网站search引擎添加，先在<a href="https://github.com/wzpan/hexo-generator-search">搜索配置官网</a>下载<strong>search.xml</strong>配置文件到文件夹中，之后在全局配置文 _config.yml文件中添加配置：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">search:</span><br><span class="line">  path: search.xml</span><br><span class="line">  field: post # post:文章范围、page:页面范围、all:覆盖所有</span><br><span class="line">  content: true # 内容是否包含每一篇文章的全部内容</span><br><span class="line">  template:  # ./search.xml 指定定制的XML模板</span><br></pre></td></tr></table></figure>在主题配置文件中修改文件<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">local_search:</span><br><span class="line">  enable: true</span><br></pre></td></tr></table></figure></li><li>标签页和分类页制作，输入以下指令：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hexo new page tags</span><br><span class="line">hexo new page categories</span><br></pre></td></tr></table></figure>之后找到source&#x2F;tags&#x2F;index.md文件和source&#x2F;categories&#x2F;index.md，添加type: “tags”或type: “categories”，最后在写每篇博文时开头可以附上tags和categories，如下所示：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">title: 利用Hexo和Butterfly主题搭建个人博客流程</span><br><span class="line">date: 2022-06-22 15:31:29</span><br><span class="line">tags:</span><br><span class="line">  - Hexo Personal Blog</span><br><span class="line">categories: </span><br><span class="line">  - Hexo</span><br><span class="line">  - 个人博客搭建</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      <categories>
          
          <category> Hexo </category>
          
          <category> 个人博客搭建 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo Personal Blog </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
