<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Pytorch第二章预备知识-线性代数</title>
      <link href="/2022/07/07/Pytorch_linear_algebra_2022_7_7/"/>
      <url>/2022/07/07/Pytorch_linear_algebra_2022_7_7/</url>
      
        <content type="html"><![CDATA[<h2 id="1-标量"><a href="#1-标量" class="headerlink" title="1. 标量"></a>1. 标量</h2><p><strong>标量</strong>：仅包含<strong>一个数值</strong>的称为标量，根据数学表示法，标量通常由<strong>小写字母表示</strong>，此外，通常用R来表示所有连续的实数标量空间。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">x = torch.tensor(3.0)</span><br><span class="line">y = torch.tensor(2.0)</span><br><span class="line"></span><br><span class="line">x + y, x * y, x/y, x**y</span><br></pre></td></tr></table></figure><h2 id="2-向量"><a href="#2-向量" class="headerlink" title="2. 向量"></a>2. 向量</h2><p><strong>向量</strong>：向量是标量组成的列表，在pytorch里通过一维张量来处理向量，张量可以有任意长度，取决于机器内存限制。通常用x_i来表示引用第i个元素。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.arange(4)</span><br><span class="line">x[3]</span><br></pre></td></tr></table></figure><p>如果一个向量由n个实值标量组成，我们可以将其表示成：$$x \in R^n$$，其中向量的长度我们通常称为<strong>维度</strong>。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">len(x) # 访问张量的长度</span><br></pre></td></tr></table></figure><p>维度有时候会引起歧义，因此规定了：向量或轴的维度被用来表示<strong>向量或轴的长度</strong>，即向量或轴的元素数量。 然而，张量的维度用来表示张量<strong>具有的轴数</strong>。 在这个意义上，张量的某个轴的维数就是这个轴的长度。</p><h2 id="3-矩阵"><a href="#3-矩阵" class="headerlink" title="3. 矩阵"></a>3. 矩阵</h2><p>通常用粗体X,Y,Z等来表示矩阵，矩阵在代码中表示有两个轴的张量。数学表示法中用A \in R^(mxn) 来表示矩阵A，其由m行n列的实值标量组成。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">A = torch.arange(20).reshape(5, 4) # 生成矩阵</span><br><span class="line">A.T # 矩阵转置</span><br><span class="line">B = torch.tensor([[1, 2, 3], [2, 0, 4], [3, 4, 5]]) # 对称矩阵，矩阵本身等于它的转置</span><br><span class="line">B == B.T</span><br></pre></td></tr></table></figure><p>尽管单个向量的默认方向是列向量，但在表示表格数据集的矩阵中， 将每个数据样本作为矩阵中的行向量更为常见。</p><h2 id="4-张量"><a href="#4-张量" class="headerlink" title="4. 张量"></a>4. 张量</h2><ol><li><p>张量加法</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">A = torch.arange(20, dtype=torch.float32).reshape(5,4))</span><br><span class="line">B = A.clone() # 通过分配新内存，将A的一个副本分配给B, A改变B不会改变</span><br><span class="line">A, A+B </span><br></pre></td></tr></table></figure></li><li><p>张量乘法<br>两个矩阵的按元素乘法称为哈达码积 (Hadamard积, Hadamard product）（数学符号⊙），如果是向量的按元素乘法，则称为点积，而且点积会计算和，哈达码积不会。<br><img src="/./img/Blog_img/7.png" alt="markdown"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A*B # A*B是对应元素相乘，如果是矩阵相乘，则用A@B或torch.matmul(A,B)</span><br></pre></td></tr></table></figure><p>将张量乘以或加上一个标量不会改变张量的形状，其中张量的每个元素都将与标量相加或相乘。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = 2</span><br><span class="line">X = torch.arange(24).shape(2,3,4)</span><br><span class="line">X+a, X*a</span><br></pre></td></tr></table></figure></li></ol><h2 id="5-降维求和"><a href="#5-降维求和" class="headerlink" title="5. 降维求和"></a>5. 降维求和</h2><p>调用求和函数会沿所有的轴降低张量的维度，使它变为一个标量。</p><ol><li><p>向量求和</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.arange(4, dtype=torch.float32)</span><br><span class="line">x, x.sum()</span><br></pre></td></tr></table></figure></li><li><p>矩阵求和</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">A = torch.arange(20, dtype=torch.float32).reshape(5,4))</span><br><span class="line">A_sum_axis0 = A.sum(axis=0) # 按行的方向来进行求和</span><br><span class="line">A_sum_axis0, A_sum_axis0.shape</span><br><span class="line"></span><br><span class="line">A_sum_axis0 = A.sum(axis=1) # 按列的方向来进行求和</span><br><span class="line">A_sum_axis0, A_sum_axis0.shape</span><br><span class="line"></span><br><span class="line">A.sum(axis=[0, 1])  # 沿着行和列对矩阵求和，等价于对矩阵的所有元素进行求和。</span><br><span class="line"></span><br><span class="line">A.mean() # 求平均值</span><br><span class="line">A.sum()/A.numel() # 求平均值</span><br><span class="line"></span><br><span class="line">A.mean(axis=0), A.sum(axis=0) / A.shape[0] # 也可以沿着某一轴进行平均值的计算</span><br></pre></td></tr></table></figure></li></ol><h2 id="6-非降维求和"><a href="#6-非降维求和" class="headerlink" title="6. 非降维求和"></a>6. 非降维求和</h2><p>有时在调用函数来计算总和或均值时保持轴数不变会很有用。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sum_A = A.sum(axis=1, keepdims=True) # keepdims=True为保持维数不变</span><br><span class="line">sum_A</span><br></pre></td></tr></table></figure><p>由于sum_A在对每行进行求和后仍保持两个轴，我们可以通过广播机制将A除以sum_A。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A / sum_A</span><br></pre></td></tr></table></figure><p>如果想沿某个轴计算A元素的<strong>累积总和</strong>，可以用cumsum函数。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A.cumsum(axis=0) # 沿着行的方向来计算累计总和</span><br></pre></td></tr></table></figure><h2 id="7-点积-Dot-product"><a href="#7-点积-Dot-product" class="headerlink" title="7. 点积(Dot product)"></a>7. 点积(Dot product)</h2><p>给定两个向量X,Y \in R^n，它们的点积为x^Ty(或&lt;x,y&gt;)是指相同位置的按元素乘积的和</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = torch.arange(4, dtype=torch.float32)</span><br><span class="line">y = torch.ones(4,dtype=torch.float32)</span><br><span class="line">x, y, torch.dot(x,y) #结果等于6</span><br></pre></td></tr></table></figure><p>x^Tw, 当权重w为非负数且所有的w和为1时，点积表示为加权平均。 将两个向量规范化得到单位长度后，点积表示它们夹角的余弦。</p><h2 id="8-矩阵-向量积"><a href="#8-矩阵-向量积" class="headerlink" title="8. 矩阵-向量积"></a>8. 矩阵-向量积</h2><p>定义矩阵 A \in R^(mxn)和向量x \in R^n, 矩阵A用它的行向量来表示：<br><img src="/./img/Blog_img/13.jpg" alt="markdown"><br>其中每个(a_1)^T都是行向量，矩阵向量积Ax是一个长度为m的列向量,其中第i个元素是a和x的点积分<br><img src="/./img/Blog_img/7.png" alt="markdown"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A.shape, x.shape, torch.mv(A, x) # 当我们为矩阵A和向量x调用torch.mv(A, x)时，会执行矩阵-向量积</span><br></pre></td></tr></table></figure><h2 id="9-矩阵-矩阵乘法"><a href="#9-矩阵-矩阵乘法" class="headerlink" title="9. 矩阵-矩阵乘法"></a>9. 矩阵-矩阵乘法</h2><p><img src="/./img/Blog_img/9.jpg" alt="markdown"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">A = torch.arange(20, dtype=torch.float32).reshape(5,4))</span><br><span class="line">B = torch.ones(4,3)</span><br><span class="line">torch.mm(4,3)</span><br></pre></td></tr></table></figure><h2 id="10-范数"><a href="#10-范数" class="headerlink" title="10. 范数"></a>10. 范数</h2><p>一个向量的范数告诉我们向量有多大，这里大小指的是分量的大小，向量范数是将向量映射到标量的函数f。<br>范数的四个性质：<br><img src="/./img/Blog_img/10.jpg" alt="markdown"></p><ol><li><p>L2范数：范数是向量元素平方和的平方根，其中L_2范数经常省略下标2，也就是说||x||等同于||x||_2，在深度学习中更常用L2范数的平方。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">u = torch.tensor([3.0, -4.0])</span><br><span class="line">torch.norm(u) # 得到L_2范数，结果为5</span><br></pre></td></tr></table></figure></li><li><p>L1范数：向量元素的绝对值之和，其与L_2范数相比，受异常值的影响较小<br><img src="/./img/Blog_img/11.jpg" alt="markdown"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.abs(u).sum()</span><br></pre></td></tr></table></figure></li><li><p>Lp范数：L2和L1范数是Lp范数的特例<br><img src="/./img/Blog_img/12.jpg" alt="markdown"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.norm(torch.ones((4, 9)))</span><br></pre></td></tr></table></figure></li></ol>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
          <category> 动手学深度学习 </category>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch第二章预备知识-数据操作+数据预处理</title>
      <link href="/2022/07/04/Pytorch_data_operation_2022_7_4/"/>
      <url>/2022/07/04/Pytorch_data_operation_2022_7_4/</url>
      
        <content type="html"><![CDATA[<p>近日一直不断观看李沐沐神的视频和书籍，想把自己的基础知识再进行不断地巩固，同时也希望可以从大神身上学习到更多系统性方面的知识和他对于这个领域的不同见解和观点，因此后续会不断更新该系列博客，将会从此书的最开头基础部分开始不断记录学习到的知识点。</p><h2 id="1-入门"><a href="#1-入门" class="headerlink" title="1. 入门"></a>1. 入门</h2><ol><li><p><strong>张量</strong>：n维数组。<strong>Tensorflow、pytorch、numpy</strong>的数据格式都是n维数组，结构类似，在Tensorflow和Pytorch中称为张量。一个轴称为<strong>向量</strong>，两个轴称为<strong>矩阵</strong>，两个轴以上的没有特殊名称。Tensor是数学上的概念，数组是计算机上的概念。<br><strong>区别</strong>：Numpy只支持CPU运算，而张量支持GPU加速运算和自动微分</p></li><li><p>基本数据操作</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line"></span><br><span class="line">x = torch.range(12) # 创建0-11的向量</span><br><span class="line"></span><br><span class="line">x.shape # 访问形状</span><br><span class="line"></span><br><span class="line">x.numel() # 得到张量中元素的总数</span><br><span class="line"></span><br><span class="line">x = x.reshape(3,4) # 改变张量的形状，变成(3,4)</span><br><span class="line"></span><br><span class="line">x = x.reshape(-1, 4) # -1代表自动计算那个维度的值</span><br><span class="line"></span><br><span class="line">torch.zeros((2,3,4)) # 创建全0</span><br><span class="line">torch.ones((2,3,4)) # 创建全1</span><br><span class="line"></span><br><span class="line">torch.randn(3,4) # 在均值为0，标准差为1的高斯正态分布中随机采样来得到张量中每个元素的值</span><br><span class="line"></span><br><span class="line">torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]]) # 用列表创建张量</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure></li></ol><h2 id="2-运算符"><a href="#2-运算符" class="headerlink" title="2. 运算符"></a>2. 运算符</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([1,2,4,8])</span><br><span class="line">y = torch.tensor([2,2,2,2])</span><br><span class="line">x+y,x-y,x*y,x/y,x**y #基本运算</span><br><span class="line"></span><br><span class="line">torch.exp(x) #求指数</span><br><span class="line"></span><br><span class="line">X = torch.arange(12,dtype=torch.float32).reshape((3,4))</span><br><span class="line">Y = torch.tensor([[2,1,4,3],[1,2,3,4],[4,3,2,1]])</span><br><span class="line">torch.cat((X,Y),dim=0),torch.cat((X,Y),dim=1) # dim=0按行方向拼接，dim=1按列方向拼接</span><br><span class="line"></span><br><span class="line">X==Y #对应位置是否相等，如果相等则True，否则False</span><br><span class="line"></span><br><span class="line">X.sum() # 对里面所有元素进行求和，输出一个值</span><br></pre></td></tr></table></figure><h2 id="3-广播机制"><a href="#3-广播机制" class="headerlink" title="3. 广播机制"></a>3. 广播机制</h2><p>形状不同，也可以调用广播机制来执行元素操作，机制：复制元素扩展一或两个数组，以便转换后，两个张量有相同形状，之后按元素操作</p><p>输入以下指令开启服务端服务(需要先开启这个，再开启客户端)</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = torch.arange(3).reshape((3,1))</span><br><span class="line">b = torch.arange(2).reshape((1,2))</span><br><span class="line"></span><br><span class="line">a+b # 会把a按列复制成3x2，接着把b按行复制成3x2，最后相加</span><br></pre></td></tr></table></figure><h2 id="4-索引和切片"><a href="#4-索引和切片" class="headerlink" title="4. 索引和切片"></a>4. 索引和切片</h2><p>张量的元素也可以通过索引访问</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">X = torch.arange(12,dtype=torch.float32).reshape((3,4))</span><br><span class="line">X[-1] # 取最后一行</span><br><span class="line">X[1:3] # 取第二第三行</span><br><span class="line">X[1,2] = 9 # 指定索引，将元素写入矩阵</span><br><span class="line">X[0:2, :] = 12 # 给第一第二行，所有列赋值</span><br><span class="line">X[::3,::2] # 第一个到最后一个，隔三行取一个值，隔二列取一个值</span><br></pre></td></tr></table></figure><h2 id="5-节省内存"><a href="#5-节省内存" class="headerlink" title="5. 节省内存"></a>5. 节省内存</h2><p>运行一些操作可能会导致为新结果分配内存。 例如，如果我们用Y &#x3D; X + Y，我们将取消引用Y指向的张量，而是指向新分配的内存处的张量。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">before = id(Y) # Y原先的内存位置</span><br><span class="line">Y = Y + X</span><br><span class="line">id(Y) == before #判断Y改变后的内存位置和原先位置是否相等</span><br></pre></td></tr></table></figure><p>该操作是不可取的，机器学习中，我们可能有数百兆的参数，我们希望原地执行这些更新。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Z = torch.zeros_like(Y)</span><br><span class="line">print(&#x27;id(Z):&#x27;, id(Z))</span><br><span class="line">Z[:] = X + Y</span><br><span class="line">print(&#x27;id(Z):&#x27;, id(Z)) #id与之前相同</span><br></pre></td></tr></table></figure><p>如果在后续计算中没有重复使用X，我们也可以使用X[:] &#x3D; X + Y或X +&#x3D; Y来减少操作的内存开销:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">before = id(X)</span><br><span class="line">X += Y</span><br><span class="line">id(X) == before</span><br></pre></td></tr></table></figure><h2 id="6-转换为其它Python对象"><a href="#6-转换为其它Python对象" class="headerlink" title="6. 转换为其它Python对象"></a>6. 转换为其它Python对象</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">A = X.numpy() # 转换成numpy格式</span><br><span class="line">B = torch.tensor(A) # 转换回Tensor</span><br><span class="line"></span><br><span class="line">a = torch.tensor([3.5])</span><br><span class="line">a.item() # 转换成Python标量</span><br><span class="line">float(a)</span><br><span class="line">int(a)</span><br></pre></td></tr></table></figure><h2 id="7-数据预处理实战"><a href="#7-数据预处理实战" class="headerlink" title="7. 数据预处理实战"></a>7. 数据预处理实战</h2><ol><li><p><strong>读取数据</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line"></span><br><span class="line">os.makedirs(os.path.join(&#x27;.&#x27;, &#x27;data&#x27;), exist_ok=True) # 创建一个文件夹</span><br><span class="line">data_file = os.path.join(&#x27;.&#x27;, &#x27;data&#x27;, &#x27;house_tiny.csv&#x27;) # 定义要创建的文件路径</span><br><span class="line">with open(data_file, &#x27;w&#x27;) as f: # 创建一个文件</span><br><span class="line">    f.write(&#x27;NumRooms,Alley,Price\n&#x27;)  # 列名</span><br><span class="line">    f.write(&#x27;NA,Pave,127500\n&#x27;)  # 每行表示一个数据样本</span><br><span class="line">    f.write(&#x27;2,NA,106000\n&#x27;) # 写入数据</span><br><span class="line">    f.write(&#x27;4,NA,178100\n&#x27;)</span><br><span class="line">    f.write(&#x27;NA,NA,140000\n&#x27;)</span><br><span class="line"></span><br><span class="line">import pandas as pd</span><br><span class="line">data = pd.read_csv(data_file) # 读取数据</span><br><span class="line">print(data)</span><br></pre></td></tr></table></figure></li><li><p><strong>处理缺失值</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">inputs, outputs = data.iloc[:, 0:2], data.iloc[:,2]</span><br><span class="line">inputs = inputs.fillna(inputs.mean()) # 用均值填充缺失值</span><br><span class="line">print(inputs)</span><br><span class="line">inputs = pd.get_dummies(inputs, dummy_na=True) # one-hot编码，dummy_na对na也进行编码</span><br></pre></td></tr></table></figure></li><li><p><strong>转换为张量格式</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line"></span><br><span class="line">X,y = torch.tensor(inputs.values), torch.tensor(outputs.values)</span><br><span class="line">X,y</span><br></pre></td></tr></table></figure></li></ol><h2 id="8-QA"><a href="#8-QA" class="headerlink" title="8. QA"></a>8. QA</h2><ol><li><p>reshape和view区别？<br>reshape和view不相同，view该操作不会开辟新的内存空间，只是产生了对原存储空间的一个新别称和引用，返回值是视图，视图值改变，原先的值也会改变。而reshape则可以开辟新的内存空间，可以是视图，也可以是新内存空间的副本。</p></li><li></li></ol>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
          <category> 动手学深度学习 </category>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>利用FRP实现内网穿透</title>
      <link href="/2022/06/26/FTP%20Intranet%20through_2022_6_25/"/>
      <url>/2022/06/26/FTP%20Intranet%20through_2022_6_25/</url>
      
        <content type="html"><![CDATA[<p>此贴记录如何通过FRP技术实现内网穿透，使通过公网指定端口可以访问至内网。FRP是一个专注于内网穿透的高性能的反向代理应用，支持 TCP、UDP、HTTP、HTTPS 等多种协议。可以将内网服务以安全、便捷的方式通过具有公网 IP 节点的中转暴露到公网。</p><h2 id="1-下载FRP库"><a href="#1-下载FRP库" class="headerlink" title="1. 下载FRP库"></a>1. 下载FRP库</h2><p>在指定文件下右键Git bash打开终端并输入以下指令下载指定版本的FRP库,不同版本链接：<a href="https://github.com/fatedier/frp/releases">https://github.com/fatedier/frp/releases</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo wget https://github.com/fatedier/frp/releases/download/v0.43.0/frp_0.43.0_linux_amd64.tar.gz</span><br></pre></td></tr></table></figure><p><img src="/./img/Blog_img/3.jpg" alt="markdown"></p><h2 id="2-解压FRP压缩包"><a href="#2-解压FRP压缩包" class="headerlink" title="2. 解压FRP压缩包"></a>2. 解压FRP压缩包</h2><p>输入以下指令进行解压(内网和外网均需要)。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf frp_0.43.0_linux_amd64.tar.gz</span><br></pre></td></tr></table></figure><h2 id="3-服务端配置文件"><a href="#3-服务端配置文件" class="headerlink" title="3. 服务端配置文件"></a>3. 服务端配置文件</h2><p>进入服务端(外网)解压的文件夹目录，之后使用以下指令打开配置文件。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim frps.ini</span><br></pre></td></tr></table></figure><p>根据下图进行配置，图中bind_port是FRP通讯的端口，要和客户端(内网)保持一致，vhost是外网开放的端口(通过外网哪个端口访问到内网服务)，同时可能需要提前关闭防火墙或打开指定端口。<br><img src="/./img/Blog_img/4.png" alt="markdown"></p><p>输入以下指令开启服务端服务(需要先开启这个，再开启客户端)</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./frps -c ./frps.ini</span><br></pre></td></tr></table></figure><h2 id="4-客户端配置文件"><a href="#4-客户端配置文件" class="headerlink" title="4. 客户端配置文件"></a>4. 客户端配置文件</h2><p>进入客户端(内网)解压的文件夹目录, 之后使用以下指令打开配置文件。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim frpc.ini</span><br></pre></td></tr></table></figure><p>根据下图进行配置，common中的地址是公网IP的地址，server_port要和上面的bind_port保持一致，web中local_port是客户端要映射的端口，remote_port是服务端开放的映射端口。<br><img src="/./img/Blog_img/5.png" alt="markdown"></p><p>输入以下指令开启客户端服务</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./frpc -c ./frpc.ini</span><br></pre></td></tr></table></figure><h2 id="5-通过systemctl来控制后台启动和开机自启"><a href="#5-通过systemctl来控制后台启动和开机自启" class="headerlink" title="5. 通过systemctl来控制后台启动和开机自启"></a>5. 通过systemctl来控制后台启动和开机自启</h2><p>输入以下指令创建新配置文件(frps和frpc):</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /lib/systemd/system/frps.service</span><br></pre></td></tr></table></figure><p>在文件中写入以下内容(服务端路径是frps，客户端路径是frpc)：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=fraps service</span><br><span class="line">After=network.target syslog.target</span><br><span class="line">Wants=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=simple</span><br><span class="line">#启动服务的命令（此处写你的frps的实际安装目录）</span><br><span class="line">ExecStart=/your/path/frps -c /your/path/frps.ini</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure><p>输入以下指令启动后台服务</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl start frps #启动frps</span><br><span class="line">sudo systemctl enable frps #打开自启动</span><br><span class="line">sudo systemctl restart frps #重启应用</span><br><span class="line">sudo systemctl stop frps #停止应用</span><br></pre></td></tr></table></figure><p><img src="/./img/Blog_img/6.png" alt="markdown"></p>]]></content>
      
      
      <categories>
          
          <category> FRP </category>
          
          <category> 内网穿透 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FRP 内网穿透 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>利用Hexo和Butterfly主题搭建个人博客流程</title>
      <link href="/2022/06/22/Building%20the%20blog_2022_6_23/"/>
      <url>/2022/06/22/Building%20the%20blog_2022_6_23/</url>
      
        <content type="html"><![CDATA[<p>此贴记录一下如何使用基于nodejs的静态博客网站生成器<strong>Hexo</strong>去生成一个个人博客，该教程以使用Butterfly主题为例进行演示。</p><h2 id="1-配置Github"><a href="#1-配置Github" class="headerlink" title="1. 配置Github"></a>1. 配置Github</h2><p>利用Github可以将本地建站的内容同步至云端存储空间中，同时利用github.io (每个账号只有一个) 提供的域名进行个人博客免费部署。</p><p>创建好Github后，建立一个为”用户名.github.io”形式的账号，并打开setting，如下图所示。同时注意要将该repo的权限变为public。</p><p><img src="/./img/Blog_img/1.jpg" alt="markdown"></p><h2 id="2-Git安装"><a href="#2-Git安装" class="headerlink" title="2. Git安装"></a>2. Git安装</h2><p>Git是一个开源的分布式版本控制系统，通过它可以方便地进行各大小项目的管理和其它人的协同合作。</p><p>进入<a href="https://git-scm.com/">Git官网</a>，下载并进行安装，全程基本点击Next即可。</p><p>下载完成后打开Git Bash，输入Git，若返回相关信息，则说明安装成功。<br><img src="/./img/Blog_img/2.jpg" alt="markdown"></p><h2 id="3-绑定Github账号"><a href="#3-绑定Github账号" class="headerlink" title="3. 绑定Github账号"></a>3. 绑定Github账号</h2><p>参考网上资料，主要是本地生成公钥密钥，然后将本地生成的公钥写入github账户中的SSH和GPGkeys这一栏中。</p><h2 id="4-利用Git提交文件的方法"><a href="#4-利用Git提交文件的方法" class="headerlink" title="4. 利用Git提交文件的方法"></a>4. 利用Git提交文件的方法</h2><h3 id="4-1-本地没有Git仓库"><a href="#4-1-本地没有Git仓库" class="headerlink" title="4.1 本地没有Git仓库"></a>4.1 本地没有Git仓库</h3><p>4.1.1 clone远程仓库的<strong>https</strong>链接<br>4.1.2 在<strong>git bash</strong>中输入<strong>git clone https链接</strong>，将远程仓库拷贝至本地<br>4.1.3 输入<strong>git status</strong>可以查看仓库状态，如果显示untracked则表示有些文件没被追踪<br>4.1.4 输入<strong>git add</strong>文件名将文件加入到缓冲区，再用<strong>git commit -m 提交信息</strong>至本地仓库，若为第一次提交则需要输入账号密码<br>4.1.5 输入<strong>git log</strong>可以查看提交记录<br>4.1.6 输入<strong>git push origin(主机名) master</strong>将本地仓库提交到远程仓库</p><h3 id="4-2-本地拥有Git仓库"><a href="#4-2-本地拥有Git仓库" class="headerlink" title="4.2 本地拥有Git仓库"></a>4.2 本地拥有Git仓库</h3><p>4.2.1 建立一个本地仓库，使用git init初始化该仓库<br>4.2.2 输入<strong>git remote add origin http链接</strong>关联远程仓库<br>4.2.3 输入<strong>git pull origin master</strong>同步远程和本地仓库，其它命令与4.1一致</p><h2 id="5-安装nodejs和Hexo"><a href="#5-安装nodejs和Hexo" class="headerlink" title="5. 安装nodejs和Hexo"></a>5. 安装nodejs和Hexo</h2><p>进入<a href="https://nodejs.org/en/">nodejs官网</a>下载nodejs并不断点击next完成安装。之后可在cmd中输入<strong>node -v</strong>查看版本。</p><p>在指定的文件夹下右键选择打开<strong>Git Bash Here</strong>并输入以下命令安装Hexo。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install -g hexo-cli</span><br></pre></td></tr></table></figure><p>安装之后输入<strong>hexo init</strong>命令初始化博客</p><p>输入以下指令生成静态文件：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo g</span><br></pre></td></tr></table></figure><p>输入以下指令运行服务器并在本地4000端口进行查看博客(修改文件时无需重启)：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo s</span><br></pre></td></tr></table></figure><p>还可以输入以下指令清除缓存文件 db.json 和已生成的静态文件：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo clean</span><br></pre></td></tr></table></figure><h2 id="6-将Hexo部署Github"><a href="#6-将Hexo部署Github" class="headerlink" title="6. 将Hexo部署Github"></a>6. 将Hexo部署Github</h2><p>在文件夹下打开全局配置文件**_config.yml**下滑到文件底部，输入以下内容：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">deploy:</span><br><span class="line">  type: git</span><br><span class="line">  repository: https://github.com/xxxxxx  #你的仓库地址</span><br><span class="line">  branch: master</span><br></pre></td></tr></table></figure><p>接着在git base中输入以下指令自动生成网站静态文件，并部署到设定的仓库，在这一步中可能需要验证账号：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo d</span><br></pre></td></tr></table></figure><h2 id="7-配置butterfly主题"><a href="#7-配置butterfly主题" class="headerlink" title="7. 配置butterfly主题"></a>7. 配置butterfly主题</h2><p>在git base中输入以下命令将butterfly主题拷贝至当前文件夹中：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/jerryc127/hexo-theme-butterfly.git</span><br></pre></td></tr></table></figure><p>在全局**_config.yml**文件中的Extensions处将主题进行修改，原主题进行注释</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">theme:butterfly</span><br></pre></td></tr></table></figure><h2 id="8-butterfly中注意事项"><a href="#8-butterfly中注意事项" class="headerlink" title="8. butterfly中注意事项"></a>8. butterfly中注意事项</h2><ul><li>在themes文件夹下的butterfly中也有一个主题配置文件_config.yml,具体配置指南可参考<a href="https://butterfly.js.org/">butterfly官网</a></li><li>网站标题、副标题和博主姓名、语言等可以在全局_config.yml文件中设置</li><li>网站search引擎添加，先在<a href="https://github.com/wzpan/hexo-generator-search">搜索配置官网</a>下载<strong>search.xml</strong>配置文件到文件夹中，之后在全局配置文 _config.yml文件中添加配置：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">search:</span><br><span class="line">  path: search.xml</span><br><span class="line">  field: post # post:文章范围、page:页面范围、all:覆盖所有</span><br><span class="line">  content: true # 内容是否包含每一篇文章的全部内容</span><br><span class="line">  template:  # ./search.xml 指定定制的XML模板</span><br></pre></td></tr></table></figure>在主题配置文件中修改文件<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">local_search:</span><br><span class="line">  enable: true</span><br></pre></td></tr></table></figure></li><li>标签页和分类页制作，输入以下指令：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hexo new page tags</span><br><span class="line">hexo new page categories</span><br></pre></td></tr></table></figure>之后找到source&#x2F;tags&#x2F;index.md文件和source&#x2F;categories&#x2F;index.md，添加type: “tags”或type: “categories”，最后在写每篇博文时开头可以附上tags和categories，如下所示：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">title: 利用Hexo和Butterfly主题搭建个人博客流程</span><br><span class="line">date: 2022-06-22 15:31:29</span><br><span class="line">tags:</span><br><span class="line">  - Hexo Personal Blog</span><br><span class="line">categories: </span><br><span class="line">  - Hexo</span><br><span class="line">  - 个人博客搭建</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      <categories>
          
          <category> Hexo </category>
          
          <category> 个人博客搭建 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo Personal Blog </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
